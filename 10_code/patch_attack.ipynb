{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 23:15:04.292145: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-14 23:15:04.292202: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-14 23:15:04.293443: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-14 23:15:04.301297: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-14 23:15:05.449650: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/workspaces/Adversarial-Patches-Experimentation/10_code/utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from scipy.ndimage import rotate\n",
    "from pretrained_models.resnet20 import ResNetCIFAR\n",
    "\n",
    "from utils import *\n",
    "from importlib import reload\n",
    "reload(sys.modules['utils'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# preapre data\n",
    "\n",
    "# PARAMS\n",
    "batch_size = 256\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "target = 1 #automobile\n",
    "\n",
    "#CIFAR-10 image tensor mean and std\n",
    "NORM_MEAN = [0.4914, 0.4822, 0.4465]\n",
    "NORM_STD = [0.2023, 0.1994, 0.2010]\n",
    "\n",
    "\n",
    "# TODO: should we apply the below transformations?\n",
    "transform_train = transforms.Compose([\n",
    "    #transforms.RandomCrop(32, padding=4),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORM_MEAN,\n",
    "                         std=NORM_STD)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORM_MEAN,\n",
    "                         std=NORM_STD)\n",
    "])\n",
    "\n",
    "transform_image = transforms.ToPILImage()\n",
    "\n",
    "print('==> Preparing data..')\n",
    "trainset = torchvision.datasets.CIFAR10(root='../00_data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../00_data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_patch_circle(patch_size):\n",
    "    radius = patch_size//2\n",
    "    patch = np.zeros(( 3, radius*2, radius*2))    \n",
    "    for i in range(3):\n",
    "        a = np.zeros((radius*2, radius*2))    \n",
    "        cx, cy = radius, radius # The center of circle \n",
    "        y, x = np.ogrid[-radius: radius, -radius: radius]\n",
    "        index = x**2 + y**2 <= radius**2\n",
    "        a[cy-radius:cy+radius, cx-radius:cx+radius][index] = np.random.rand()\n",
    "        idx = np.flatnonzero((a == 0).all((1)))\n",
    "        a = np.delete(a, idx, axis=0)\n",
    "        patch[i] = np.delete(a, idx, axis=1)\n",
    "    return patch\n",
    "# init a circle path and visualize it\n",
    "patch = init_patch_circle(patch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR_MEANS, TENSOR_STD = torch.FloatTensor(NORM_MEAN)[:,None,None], torch.FloatTensor(NORM_STD)[:,None,None]\n",
    "def patch_forward(patch):\n",
    "    # Map patch values from [-infty,infty] to ImageNet min and max\n",
    "    patch = (torch.tanh(patch) + 1 - 2 * TENSOR_MEANS) / (2 * TENSOR_STD)\n",
    "    return patch\n",
    "\n",
    "\n",
    "def place_patch(img, patch):\n",
    "    \n",
    "    for i in range(img.shape[0]): # number of channels\n",
    "        # rot = np.random.choice(360)   \n",
    "        # patch = torch.from_numpy(rotate(patch.detach().numpy(), rot, axes = (1,2), reshape=False))\n",
    "        h_offset = np.random.randint(0,img.shape[2]-patch.shape[1]-1)\n",
    "        w_offset = np.random.randint(0,img.shape[3]-patch.shape[2]-1)\n",
    "        img[i,:,h_offset:h_offset+patch.shape[1],w_offset:w_offset+patch.shape[2]] = patch_forward(patch)\n",
    "    \n",
    "    return img # ,rot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targeted Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_patch(model, patch, val_loader, target_class):\n",
    "    model.eval()\n",
    "    tp, tp_5, counter = 0., 0., 0.\n",
    "    n = 0 # number of images\n",
    "    with torch.no_grad():\n",
    "        for img, img_labels in tqdm(val_loader, desc=\"Validating...\", leave=False):\n",
    "            # For stability, place the patch at 4 random locations per image, and average the performance\n",
    "            for _ in range(4):\n",
    "                patch_img = place_patch(img, patch)\n",
    "                patch_img = patch_img.to(device)\n",
    "                img_labels = img_labels.to(device)\n",
    "                pred = model(patch_img)\n",
    "                # In the accuracy calculation, we need to exclude the images that are of our target class\n",
    "                # as we would not \"fool\" the model into predicting those\n",
    "                tp += torch.logical_and(pred.argmax(dim=-1) == target_class, img_labels != target_class).sum()\n",
    "                tp_5 += torch.logical_and((pred.topk(5, dim=-1)[1] == target_class).any(dim=-1), img_labels != target_class).sum()\n",
    "                counter += (img_labels != target_class).sum()\n",
    "                n += (img_labels != target_class).sum()\n",
    "    acc = tp/counter\n",
    "    top5 = tp_5/counter\n",
    "    attack_success_rate = tp/n\n",
    "    return acc, top5, attack_success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_attack_targeted(model, target_class, patch_size, num_epochs=5):\n",
    "    # Leave a small set of images out to check generalization\n",
    "    # In most of our experiments, the performance on the hold-out data points\n",
    "    # was as good as on the training set. Overfitting was little possible due\n",
    "    # to the small size of the patches.\n",
    "    train_set, val_set = torch.utils.data.random_split(trainset, [0.8, 0.2])\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last = True, num_workers=4)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=False, drop_last=False, num_workers=4)\n",
    "\n",
    "    # Create parameter and optimizer\n",
    "    # if not isinstance(patch_size, tuple):\n",
    "    #     patch_size = (patch_size, patch_size)\n",
    "    patch = nn.Parameter(torch.tensor(init_patch_circle(patch_size)), requires_grad= True)#nn.Parameter(torch.zeros(3, patch_size[0], patch_size[1]), requires_grad=True)\n",
    "    optimizer = torch.optim.SGD([patch], lr=1e-1, momentum=0.8)\n",
    "    loss_module = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        t = tqdm(train_loader, leave=False)\n",
    "        for img, _ in t:\n",
    "            img = place_patch(img, patch)\n",
    "            img = img.to(device)\n",
    "            pred = model(img)\n",
    "            labels = torch.zeros(img.shape[0], device=pred.device, dtype=torch.long).fill_(target_class)\n",
    "            loss = loss_module(pred, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            optimizer.step()\n",
    "            t.set_description(f\"Epoch {epoch}, Loss: {loss.item():4.2f}\")\n",
    "        if epoch % 5 == 0:\n",
    "            acc, top5, attack_success_rate = eval_patch(model, patch, val_loader, target_class)\n",
    "            print(f\"Epoch {epoch}, Attack Success Rate: {attack_success_rate.item()}.\")\n",
    "\n",
    "    # Final validation\n",
    "    # acc, top5, attack_success_rate = eval_patch(model, patch, val_loader, target_class)\n",
    "\n",
    "    return patch.data, {\"acc\": acc.item(), \"top5\": top5.item(), \"attack_success_rate\": attack_success_rate.item()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the Pre-Trained ResNet-20 model\n",
    "net = ResNetCIFAR(num_layers=20, Nbits=None)\n",
    "net = net.to(device)\n",
    "net.load_state_dict(torch.load(\"./pretrained_models/pretrained_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Attack Success Rate: 0.3535367548465729.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Attack Success Rate: 0.9400242567062378.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Attack Success Rate: 0.9476109147071838.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Attack Success Rate: 0.9540388584136963.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    }
   ],
   "source": [
    "p, x = patch_attack_targeted(net, target_class=1, patch_size=16, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "acc, top5, attack_success_rate = eval_patch(net, p, testloader, target_class=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Untargeted Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_patch_untarget(model, patch, val_loader):\n",
    "    model.eval()\n",
    "    tp  = 0\n",
    "    n = 0 # number of images\n",
    "    with torch.no_grad():\n",
    "        for img, img_labels in tqdm(val_loader, desc=\"Validating...\", leave=False):\n",
    "            # For stability, place the patch at 4 random locations per image, and average the performance\n",
    "            for _ in range(4):\n",
    "                patch_img = place_patch(img, patch)\n",
    "                patch_img = patch_img.to(device)\n",
    "                img_labels = img_labels.to(device)\n",
    "                pred = model(patch_img)\n",
    "                # In the accuracy calculation, we need to exclude the images that are of our target class\n",
    "                # as we would not \"fool\" the model into predicting those\n",
    "                # get number of incorrect predictions\n",
    "                tp += (pred.argmax(dim=-1) != img_labels).sum()\n",
    "                n += img_labels.shape[0]\n",
    "\n",
    "    attack_success_rate = tp/n\n",
    "    return attack_success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_attack_untargeted(model, patch_size=16, num_epochs=5):\n",
    "    train_set, val_set = torch.utils.data.random_split(trainset, [0.8, 0.2])\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last = True, num_workers=4)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=False, drop_last=False, num_workers=4)\n",
    "    \n",
    "    patch = nn.Parameter(torch.tensor(init_patch_circle(patch_size)), requires_grad= True)\n",
    "    optimizer = torch.optim.SGD([patch], lr=1e-1, momentum=0.8)\n",
    "    loss_module = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        t = tqdm(train_loader, leave=False)\n",
    "        for img, labels in t:\n",
    "            img = place_patch(img, patch)\n",
    "            img = img.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = model(img)\n",
    "            loss = - loss_module(pred, labels) # make it negative to maximize the loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            optimizer.step()\n",
    "            t.set_description(f\"Epoch {epoch}, Loss: {loss.item():4.2f}\")\n",
    "        if epoch % 5 == 0:\n",
    "            attack_success_rate = eval_patch_untarget(model, patch, val_loader)\n",
    "            print(f\"Epoch {epoch}, Attack Success Rate: {attack_success_rate.item()}.\")\n",
    "\n",
    "    # Final validation\n",
    "    attack_success_rate = eval_patch_untarget(model, patch, val_loader)\n",
    "    print(f\"Epoch {epoch}, Attack Success Rate: {attack_success_rate.item()}.\")\n",
    "\n",
    "    return patch.data, attack_success_rate.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the Pre-Trained ResNet-20 model\n",
    "net = ResNetCIFAR(num_layers=20, Nbits=None)\n",
    "net = net.to(device)\n",
    "net.load_state_dict(torch.load(\"./pretrained_models/pretrained_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Attack Success Rate: 0.38804998993873596.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Attack Success Rate: 0.6696749925613403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Attack Success Rate: 0.6963749527931213.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Attack Success Rate: 0.7126249670982361.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    }
   ],
   "source": [
    "up, ux = patch_attack_untargeted(net, patch_size=8, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Attack Success Rate: 0.1868249922990799.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Attack Success Rate: 0.36864998936653137.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Attack Success Rate: 0.4077000021934509.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Attack Success Rate: 0.4100499749183655.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    }
   ],
   "source": [
    "# load the Pre-Trained ResNet-20 model\n",
    "net = ResNetCIFAR(num_layers=20, Nbits=None)\n",
    "net = net.to(device)\n",
    "net.load_state_dict(torch.load(\"./pretrained_models/pretrained_model.pt\"))\n",
    "up, ux = patch_attack_untargeted(net, patch_size=5, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4092499911785126"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
